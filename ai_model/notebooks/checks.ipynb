{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.29.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\haida\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\haida\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (24.2)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\haida\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\haida\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.26.0->transformers)\n",
      "  Downloading fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\haida\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\haida\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\haida\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\haida\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\haida\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\haida\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Using cached transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "Downloading huggingface_hub-0.29.2-py3-none-any.whl (468 kB)\n",
      "Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl (156 kB)\n",
      "Downloading regex-2024.11.6-cp313-cp313-win_amd64.whl (273 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "Installing collected packages: safetensors, regex, pyyaml, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed filelock-3.17.0 fsspec-2025.2.0 huggingface-hub-0.29.2 pyyaml-6.0.2 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.0 transformers-4.49.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_id\tpath\tsentence\tup_votes\tdown_votes\tage\tgender\taccents\tvariant\tlocale\tsegment\n",
      "e53f84d151d6cc6d45a57decde08a99efe47d7751a4ca60e58fb87ea68a35d53dcae445c65d5e73e0449a0b1cf2b4d09f32874877e8786664aa50f1f2ec2b932\tcommon_voice_ur_31771683.wav\tکبھی کبھار ہی خیالی پلاو بناتا ہوں\t2\t0\ttwenties\tmale\t\t\tur\n",
      "e53f84d151d6cc6d45a57decde08a99efe47d7751a4ca60e58fb87ea68a35d53dcae445c65d5e73e0449a0b1cf2b4d09f32874877e8786664aa50f1f2ec2b932\tcommon_voice_ur_31771684.wav\tاور پھر ممکن ہے کہ پاکستان بھی ہو\t2\t1\ttwenties\tmale\t\t\tur\n",
      "e53f84d151d6cc6d45a57decde08a99efe47d7751a4ca60e58fb87ea68a35d53dcae445c65d5e73e0449a0b1cf2b4d09f32874877e8786664aa50f1f2ec2b932\tcommon_voice_ur_31771685.wav\tیہ فیصلہ بھی گزشتہ دو سال میں\t2\t0\ttwenties\tmale\t\t\tur\n",
      "e53f84d151d6cc6d45a57decde08a99efe47d7751a4ca60e58fb87ea68a35d53dcae445c65d5e73e0449a0b1cf2b4d09f32874877e8786664aa50f1f2ec2b932\tcommon_voice_ur_31771730.wav\tان کے بلے بازوں کے سامنے ہو گا\t3\t0\ttwenties\tmale\t\t\tur\n",
      "e53f84d151d6cc6d45a57decde08a99efe47d7751a4ca60e58fb87ea68a35d53dcae445c65d5e73e0449a0b1cf2b4d09f32874877e8786664aa50f1f2ec2b932\tcommon_voice_ur_31771732.wav\tآبی جانور میں بطخ بگلا اور دُوسْرا آبی پرندہ شامل ہونا\t3\t0\ttwenties\tmale\t\t\tur\n",
      "e53f84d151d6cc6d45a57decde08a99efe47d7751a4ca60e58fb87ea68a35d53dcae445c65d5e73e0449a0b1cf2b4d09f32874877e8786664aa50f1f2ec2b932\tcommon_voice_ur_31771880.wav\tاِس طےشدہ مدت میں میرے ذمے پڑھانے کا کام کافی ہلکا ہے\t2\t0\ttwenties\tmale\t\t\tur\n",
      "e53f84d151d6cc6d45a57decde08a99efe47d7751a4ca60e58fb87ea68a35d53dcae445c65d5e73e0449a0b1cf2b4d09f32874877e8786664aa50f1f2ec2b932\tcommon_voice_ur_31771882.wav\tفلمیں دیکھنی ہوں۔\t2\t0\ttwenties\tmale\t\t\tur\n",
      "e53f84d151d6cc6d45a57decde08a99efe47d7751a4ca60e58fb87ea68a35d53dcae445c65d5e73e0449a0b1cf2b4d09f32874877e8786664aa50f1f2ec2b932\tcommon_voice_ur_31771884.wav\tدوسرا اس وجہ سے کہ اس کی پشت پر ذرائع ابلاغ ہیں۔\t2\t1\ttwenties\tmale\t\t\tur\n",
      "e53f84d151d6cc6d45a57decde08a99efe47d7751a4ca60e58fb87ea68a35d53dcae445c65d5e73e0449a0b1cf2b4d09f32874877e8786664aa50f1f2ec2b932\tcommon_voice_ur_31771885.wav\tاسکے معانی پر اور مفہوم پر کبھی غورکیا بھی نہیں\t2\t0\ttwenties\tmale\t\t\tur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\A'\n",
      "C:\\Users\\haida\\AppData\\Local\\Temp\\ipykernel_68\\3804926752.py:1: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  with open(\"E:\\AI-Driven-Call-Center-Issue-Analysis-System---FYP\\\\ai_model\\data\\dataset.tsv\", \"r\", encoding=\"utf-8\") as f:\n"
     ]
    }
   ],
   "source": [
    "with open(\"E:\\AI-Driven-Call-Center-Issue-Analysis-System---FYP\\\\ai_model\\data\\dataset.tsv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for i in range(10):  # Print first 10 lines\n",
    "        print(f.readline().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jiwer\n",
      "  Using cached jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting click>=8.1.8 (from jiwer)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
      "  Downloading rapidfuzz-3.12.2-cp313-cp313-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\haida\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from click>=8.1.8->jiwer) (0.4.6)\n",
      "Using cached jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading rapidfuzz-3.12.2-cp313-cp313-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.5/1.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 6.3 MB/s eta 0:00:00\n",
      "Installing collected packages: rapidfuzz, click, jiwer\n",
      "Successfully installed click-8.1.8 jiwer-3.1.0 rapidfuzz-3.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from jiwer import wer\n",
    "\n",
    "# Load transcriptions\n",
    "df = pd.read_csv(r\"E:\\AI-Driven-Call-Center-Issue-Analysis-System---FYP\\\\ai_model\\data\\\\talha_transcriptions.csv\")\n",
    "\n",
    "# Load original ground-truth transcriptions\n",
    "df_original = pd.read_csv(r\"E:\\AI-Driven-Call-Center-Issue-Analysis-System---FYP\\\\ai_model\\data\\\\processed_data\\\\encoded_dataset.csv\")  \n",
    "\n",
    "# Merge both dataframes on the 'path' column\n",
    "df_merged = df.merge(df_original, on=\"path\", suffixes=(\"_transcribed\", \"_original\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged columns: Index(['path', 'transcription', 'client_id', 'sentence', 'up_votes',\n",
      "       'down_votes', 'age', 'gender', 'accents', 'variant', 'locale',\n",
      "       'segment', 'encoded_text'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Merged columns:\", df_merged.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"sentence\"] = df_merged[\"sentence\"].fillna(\"\").astype(str)\n",
    "df_merged[\"transcription\"] = df_merged[\"transcription\"].fillna(\"\").astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall WER: 28.73%\n"
     ]
    }
   ],
   "source": [
    "overall_wer = wer(\" \".join(df_merged[\"sentence\"]), \" \".join(df_merged[\"transcription\"]))\n",
    "\n",
    "print(f\"Overall WER: {overall_wer:.2%}\")  # Display as a percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.6.0-cp313-cp313-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\haida\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\haida\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (4.12.2)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\haida\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (2025.2.0)\n",
      "Collecting setuptools (from torch)\n",
      "  Using cached setuptools-75.8.2-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
      "Downloading torch-2.6.0-cp313-cp313-win_amd64.whl (204.1 MB)\n",
      "   ---------------------------------------- 0.0/204.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/204.1 MB 9.4 MB/s eta 0:00:22\n",
      "    --------------------------------------- 3.9/204.1 MB 11.7 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 6.6/204.1 MB 12.5 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 9.2/204.1 MB 12.1 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 12.3/204.1 MB 12.7 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 15.2/204.1 MB 13.0 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 18.4/204.1 MB 13.2 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 21.8/204.1 MB 13.4 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 24.6/204.1 MB 13.5 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 27.5/204.1 MB 13.5 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 30.4/204.1 MB 13.6 MB/s eta 0:00:13\n",
      "   ------ --------------------------------- 33.6/204.1 MB 13.6 MB/s eta 0:00:13\n",
      "   ------ --------------------------------- 34.9/204.1 MB 13.7 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 38.8/204.1 MB 13.5 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 41.7/204.1 MB 13.5 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 44.3/204.1 MB 13.5 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 47.4/204.1 MB 13.5 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 50.6/204.1 MB 13.6 MB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 53.0/204.1 MB 13.4 MB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 54.3/204.1 MB 13.1 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 57.1/204.1 MB 13.1 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 60.0/204.1 MB 13.1 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 62.9/204.1 MB 13.2 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 66.1/204.1 MB 13.2 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 69.2/204.1 MB 13.2 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 72.1/204.1 MB 13.3 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 74.4/204.1 MB 13.2 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 77.1/204.1 MB 13.2 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 79.4/204.1 MB 13.1 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 82.3/204.1 MB 13.1 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 85.2/204.1 MB 13.1 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 87.8/204.1 MB 13.1 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 91.0/204.1 MB 13.1 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 93.8/204.1 MB 13.2 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 95.2/204.1 MB 13.1 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 97.0/204.1 MB 12.8 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 100.1/204.1 MB 12.9 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 102.8/204.1 MB 12.9 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 105.9/204.1 MB 12.9 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 108.0/204.1 MB 12.9 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 110.9/204.1 MB 12.9 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 113.5/204.1 MB 12.9 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 116.4/204.1 MB 12.9 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 118.8/204.1 MB 12.9 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 120.6/204.1 MB 12.8 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 123.5/204.1 MB 12.8 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 126.6/204.1 MB 12.8 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 129.5/204.1 MB 12.9 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 132.6/204.1 MB 12.9 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 135.5/204.1 MB 12.9 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 138.4/204.1 MB 13.0 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 141.6/204.1 MB 13.0 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 144.7/204.1 MB 13.0 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 147.6/204.1 MB 13.0 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 149.9/204.1 MB 13.0 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 153.1/204.1 MB 13.1 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 156.0/204.1 MB 13.1 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 159.1/204.1 MB 13.1 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 162.0/204.1 MB 13.1 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 165.2/204.1 MB 13.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 168.3/204.1 MB 13.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 171.2/204.1 MB 13.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 174.6/204.1 MB 13.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 176.9/204.1 MB 13.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 179.8/204.1 MB 13.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 182.7/204.1 MB 13.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 185.6/204.1 MB 13.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 188.5/204.1 MB 13.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 191.6/204.1 MB 13.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 194.8/204.1 MB 13.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 197.9/204.1 MB 13.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  200.8/204.1 MB 13.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.7/204.1 MB 13.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.9/204.1 MB 13.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.9/204.1 MB 13.3 MB/s eta 0:00:01\n",
      "   --------------------------------------- 204.1/204.1 MB 13.0 MB/s eta 0:00:00\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached setuptools-75.8.2-py3-none-any.whl (1.2 MB)\n",
      "Downloading MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, setuptools, networkx, MarkupSafe, jinja2, torch\n",
      "Successfully installed MarkupSafe-3.0.2 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 setuptools-75.8.2 sympy-1.13.1 torch-2.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nMBartForConditionalGeneration requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mabdulwaheed1/urdu_to_english_translation_mbart\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m tokenizer = MBart50TokenizerFast.from_pretrained(model_name)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m model = \u001b[43mMBartForConditionalGeneration\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m(model_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\haida\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1736\u001b[39m, in \u001b[36mDummyObject.__getattribute__\u001b[39m\u001b[34m(cls, key)\u001b[39m\n\u001b[32m   1734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key.startswith(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key != \u001b[33m\"\u001b[39m\u001b[33m_from_config\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1735\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\haida\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1724\u001b[39m, in \u001b[36mrequires_backends\u001b[39m\u001b[34m(obj, backends)\u001b[39m\n\u001b[32m   1722\u001b[39m failed = [msg.format(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[32m   1723\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[32m-> \u001b[39m\u001b[32m1724\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(failed))\n",
      "\u001b[31mImportError\u001b[39m: \nMBartForConditionalGeneration requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "\n",
    "# Load the tokenizer and model\n",
    "model_name = \"abdulwaheed1/urdu_to_english_translation_mbart\"\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(model_name)\n",
    "model = MBartForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
